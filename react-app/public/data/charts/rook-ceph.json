{
  "name": "rook-ceph",
  "repo": "rook",
  "description": "Rook-Ceph is an open source cloud-native storage orchestrator for Kubernetes, providing simplified management, deployment, and scaling of Ceph storage clusters. It enables storage to be consumed as a self-managing, self-optimizing, and self-healing service.",
  "version": "1.16.0",
  "appVersion": "19.2.0",
  "values": "# Rook-Ceph configuration\n# Ref: https://github.com/rook/rook/blob/master/deploy/charts/rook-ceph/values.yaml\n\n## Global settings\nglobal:\n  imageRegistry: \"\"\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## Rook-Ceph operator settings\noperator:\n  ## Rook-Ceph operator image settings\n  image:\n    repository: rook/ceph\n    tag: \"v1.16.0\"\n    pullPolicy: IfNotPresent\n  \n  ## Resources settings\n  resources:\n    limits:\n      cpu: 500m\n      memory: 512Mi\n    requests:\n      cpu: 250m\n      memory: 256Mi\n  \n  ## Node selector\n  nodeSelector: {}\n  \n  ## Tolerations\n  tolerations: []\n  \n  ## Affinity\n  affinity: {}\n  \n  ## Priority class\n  priorityClassName: \"\"\n  \n  ## Pod security context\n  podSecurityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    runAsGroup: 1000\n    fsGroup: 1000\n  \n  ## Security context\n  securityContext:\n    capabilities:\n      drop:\n        - ALL\n  \n  ## Service account\n  serviceAccount:\n    create: true\n    name: \"\"\n  \n  ## RBAC settings\n  rbac:\n    create: true\n  \n  ## Monitoring settings\n  monitoring:\n    enabled: false\n    createPrometheusRules: false\n    \n  ## Logging settings\n  logLevel: \"INFO\"\n\n## Ceph cluster settings\ncephCluster:\n  enabled: true\n  \n  ## Ceph cluster name\n  name: \"rook-ceph\"\n  \n  ## Ceph cluster configuration\n  config:\n    ## Monitors settings\n    mon:\n      count: 3\n      allowMultiplePerNode: false\n      \n    ## Manager settings\n    mgr:\n      count: 1\n      \n    ## OSD settings\n    osd:\n      ## Device filter (can be device name, partition, or path)\n      deviceFilter: \"\"\n      ## Directories to use for OSDs\n      directories: []\n      ## Store type (bluestore or filestore)\n      storeType: \"bluestore\"\n      \n    ## Placement settings\n    placement:\n      all:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                  - key: role\n                    operator: In\n                    values:\n                      - storage-node\n        \n    ## Resource settings\n    resources:\n      mon:\n        limits:\n          cpu: 1000m\n          memory: 1Gi\n        requests:\n          cpu: 500m\n          memory: 512Mi\n      mgr:\n        limits:\n          cpu: 1000m\n          memory: 1Gi\n        requests:\n          cpu: 500m\n          memory: 512Mi\n      osd:\n        limits:\n          cpu: 2000m\n          memory: 2Gi\n        requests:\n          cpu: 1000m\n          memory: 1Gi\n      \n    ## Storage settings\n    storage:\n      ## Use all devices\n      useAllDevices: true\n      ## Device filter\n      deviceFilter: \"\"\n      ## Device path filter\n      devicePathFilter: \"\"\n      ## Nodes to use\n      nodes: []\n      \n    ## Dashboard settings\n    dashboard:\n      enabled: true\n      urlPrefix: \"\"\n      port: 8443\n      ssl: true\n      \n    ## Monitoring settings\n    monitoring:\n      enabled: true\n      rulesNamespace: \"\"\n      \n    ## Crash collector settings\n    crashCollector:\n      disable: false\n\n## Ceph filesystem settings\ncephFilesystem:\n  enabled: false\n  \n  ## Filesystem name\n  name: \"myfs\"\n  \n  ## Number of active MDS instances\n  activeCount: 1\n  \n  ## Pool settings\n  pool:\n    replicated:\n      size: 3\n\n## Ceph block pool settings\ncephBlockPool:\n  enabled: false\n  \n  ## Block pool name\n  name: \"replicapool\"\n  \n  ## Replication settings\n  replicated:\n    size: 3\n    \n  ## Erasure coding settings\n  erasureCoded:\n    codingChunks: 1\n    dataChunks: 2\n\n## Ceph object store settings\ncephObjectStore:\n  enabled: false\n  \n  ## Object store name\n  name: \"my-store\"\n  \n  ## Number of RGW instances\n  instances: 1\n  \n  ## Gateway settings\n  gateway:\n    port: 80\n    securePort: 443\n    instances: 1\n    \n  ## Zone settings\n  zone:\n    name: \"default\"\n\n## Ceph toolbox settings\ntoolbox:\n  enabled: true\n  \n  ## Toolbox image settings\n  image:\n    repository: rook/ceph\n    tag: \"v1.16.0\"\n    pullPolicy: IfNotPresent\n  \n  ## Resources settings\n  resources:\n    limits:\n      cpu: 500m\n      memory: 512Mi\n    requests:\n      cpu: 250m\n      memory: 256Mi\n\n## CSI driver settings\ncsi:\n  ## Enable CSI driver\n  enable:\n    rbd: true\n    cephfs: true\n    nfs: false\n  \n  ## CSI driver image settings\n  image:\n    repository: quay.io/cephcsi/cephcsi\n    tag: \"v3.12.0\"\n    pullPolicy: IfNotPresent\n  \n  ## Provisioner settings\n  provisioner:\n    replicas: 2\n    \n  ## Attacher settings\n  attacher:\n    replicas: 2\n    \n  ## Snapshotter settings\n  snapshotter:\n    replicas: 2\n    \n  ## Resizer settings\n  resizer:\n    replicas: 2\n    \n  ## Node plugin settings\n  nodePlugin:\n    \n  ## Resources settings\n  resources:\n    csiProvisioner:\n      limits:\n        cpu: 200m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    csiAttacher:\n      limits:\n        cpu: 200m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    csiSnapshotter:\n      limits:\n        cpu: 200m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    csiResizer:\n      limits:\n        cpu: 200m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    csiDriverRegistrar:\n      limits:\n        cpu: 200m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n\n## Monitoring settings\nmonitoring:\n  enabled: false\n  createPrometheusRules: false\n  \n  ## Service monitor settings\n  serviceMonitor:\n    enabled: false\n    interval: 5s\n    \n  ## Prometheus rules settings\n  prometheusRules:\n    enabled: false\n\n## Security settings\nsecurity:\n  ## Kubernetes secrets settings\n  kms: {}\n  \n  ## Encryption settings\n  encryption:\n    enabled: false\n\n## Network settings\nnetwork:\n  provider: \"\"\n  selectors: {}\n\n## Cleanup settings\ncleanup:\n  ## Wait for cleanup\n  waitForCleanup: true\n  \n  ## Remove OSDs on cleanup\n  removeOSDsOnDestroy: false\n\n## Admission controller settings\nadmissionController:\n  enabled: true\n  \n  ## Admission controller image settings\n  image:\n    repository: rook/ceph\n    tag: \"v1.16.0\"\n    pullPolicy: IfNotPresent\n  \n  ## Resources settings\n  resources:\n    limits:\n      cpu: 100m\n      memory: 128Mi\n    requests:\n      cpu: 50m\n      memory: 64Mi",
  "url": "https://github.com/rook/rook/tree/master/deploy/charts/rook-ceph",
  "createdAt": "2025-10-03"
}